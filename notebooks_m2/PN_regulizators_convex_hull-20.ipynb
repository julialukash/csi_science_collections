{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import artm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "print artm.version()\n",
    "\n",
    "from os import path, mkdir\n",
    "from datetime import datetime\n",
    "sys.path.insert(0, '..\\\\modules\\\\helpers')\n",
    "\n",
    "import distances_helper as dh \n",
    "import print_helper as ph\n",
    "import create_model_helper as cmh\n",
    "import build_convex_hull_helper as bchh\n",
    "import test_vs_original_columns_helper as tvsoch\n",
    "import compare_two_models as ctm\n",
    "\n",
    "from plot_helper import PlotMaker\n",
    "from config_helper import ConfigPaths\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "Input config file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-185041d63c2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfigPaths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'config_sample_2.cfg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels_file_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodels_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels_file_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot_maker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPlotMaker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mF:\\topic_modeling\\csi_science_collections.no_git\\modules\\helpers\\config_helper.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_name)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input config file not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfigparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfigParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Input config file not found"
     ]
    }
   ],
   "source": [
    "config = ConfigPaths('config_sample_2.cfg')\n",
    "print config.models_file_name\n",
    "models_file = open(config.models_file_name, 'a')\n",
    "\n",
    "plot_maker = PlotMaker()\n",
    "\n",
    "batch_vectorizer = artm.BatchVectorizer(data_path=config.output_batches_path,\n",
    "                                        data_format='batches')\n",
    "dictionary = artm.Dictionary()\n",
    "dictionary.load(dictionary_path=config.dictionary_path + '.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def save_pickle_file(dists, filename, _path=config.experiment_path):\n",
    "    pickle_filename = path.join(_path, filename)\n",
    "    pickle_file = open(pickle_filename, 'wb')\n",
    "    pickle.dump(dists, pickle_file)\n",
    "    pickle_file.close()\n",
    "def load_pickle_file(filename, _path=config.experiment_path):\n",
    "    pickle_filename = path.join(_path, filename)\n",
    "    pickle_file = open(pickle_filename, 'rb')\n",
    "    p_file = pickle.load(pickle_file)\n",
    "    pickle_file.close()\n",
    "    return p_file\n",
    "def plot_convex_hull_topics_iterations_distribution(_phi_convex_hull):\n",
    "    get_iteration_number_fn = lambda x: int(x[x.find('_', 6) + 1 : ])\n",
    "    phi_convex_hull_iteration_number = [get_iteration_number_fn(col) for col in _phi_convex_hull.columns]\n",
    "    phi_convex_hull_iteration_number = [(val, phi_convex_hull_iteration_number.count(val), 1.0 * phi_convex_hull_iteration_number.count(val) / len(phi_convex_hull_iteration_number)) for val in set(phi_convex_hull_iteration_number)]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False, figsize=(15,5))\n",
    "    sns.barplot([x[0] for x in phi_convex_hull_iteration_number], [x[1] for x in phi_convex_hull_iteration_number], ax=ax1)\n",
    "    ax1.set_title('Number of topics from each iteration')\n",
    "    ax1.set_xlabel('n iteration')\n",
    "\n",
    "    sns.barplot([x[0] for x in phi_convex_hull_iteration_number], [x[2] for x in phi_convex_hull_iteration_number], ax=ax2)\n",
    "    ax2.set_title('Number of topics from each iteration (%)')\n",
    "    ax2.set_xlabel('n iteration')\n",
    "def plot_convex_hull_columns_change(iterations_info):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False, figsize=(15,5))\n",
    "    ax1.plot([sum([val['n_topics_to_remove']for val in it['iterations_info_filter']]) for it in iterations_info], \n",
    "             color='r', label = 'total')\n",
    "    ax1.set_title('Num columns to remove')\n",
    "    get_topic_iteration_fn = lambda x: int(x[x.rfind('_') + 1 :])\n",
    "    get_topic_filter_iteration_list_fn = lambda x, y: [get_topic_iteration_fn(topic) for topic in x].count(y)\n",
    "    n_topics_removed_from_current_iteration = [sum([get_topic_filter_iteration_list_fn(val['removed_topics'], indx) for val in it['iterations_info_filter']]) for indx, it in enumerate(iterations_info)]\n",
    "    ax1.plot(n_topics_removed_from_current_iteration, color='b', label='current iteration')\n",
    "    ax1.set_xlabel('n iteration')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot([val['phi_convex_hull_shape'][1] for val in iterations_info], color='r')\n",
    "    ax2.set_title('Num columns of convex hull')\n",
    "    ax2.set_xlabel('n iteration')\n",
    "    ax2.legend()\n",
    "def plot_opt_res_fun(iterations_filtering_info_name):\n",
    "    %matplotlib inline\n",
    "    iterations_filtering_info = load_pickle_file(iterations_filtering_info_name)\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False, figsize=(15,5))\n",
    "    values = [x.fun for item in iterations_filtering_info for val in item for x in val['opt_res'].values()]\n",
    "    sns.distplot(values, color='r', bins=10, ax=ax1)\n",
    "    values = [[x.fun for val in item for x in val['opt_res'].values()] for item in iterations_filtering_info]\n",
    "    for val in values:\n",
    "        sns.distplot(val, bins=10, ax=ax2)\n",
    "def plot_opt_res_fun_filtering(iterations_filtering_info_name):\n",
    "    iterations_info = load_pickle_file(iterations_filtering_info_name)\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False, figsize=(15,5))\n",
    "    values = [x.fun for item in iterations_info for val in item['iterations_info_filter'] for x in val['opt_res'].values()]\n",
    "    sns.distplot(values, color='r', bins=10, ax=ax1)\n",
    "    values = [[x.fun for val in item['iterations_info_filter'] for x in val['opt_res'].values()] for item in iterations_info]\n",
    "    for val in values:\n",
    "        sns.distplot(val, bins=10, ax=ax2)\n",
    "def get_phi_granularity(phi):\n",
    "    return np.mean([get_words_close_to_th_count(col)[0] for topic, col in phi.iteritems()])\n",
    "def get_words_close_to_th_count(col, global_th=0.95):\n",
    "    cur_sum, sum_count = 0, 0\n",
    "    for val in col.sort_values()[::-1]:\n",
    "        if cur_sum + val <= global_th:\n",
    "            cur_sum += val\n",
    "            sum_count += 1\n",
    "        else:\n",
    "            break\n",
    "    return sum_count + 1, cur_sum\n",
    "def get_opt_x_granularity(opt):\n",
    "    return np.mean([get_opt_x_close_to_th_count(opt_res.x)[0] for topic, opt_res in opt.iteritems()])\n",
    "def get_opt_x_close_to_th_count(opt_x, cut_th=None, global_th=0.95):\n",
    "    cur_sum, sum_count = 0, 0\n",
    "    opt_x_val = opt_x.copy()\n",
    "    if cut_th != None:\n",
    "        opt_x_val[opt_x_val < cut_th] = 0\n",
    "    for val in sorted(opt_x_val)[::-1]:\n",
    "        if val !=0 and cur_sum + val <= global_th:\n",
    "            cur_sum += val\n",
    "            sum_count += 1\n",
    "        else:\n",
    "            break\n",
    "    return sum_count + 1, cur_sum\n",
    "def get_and_plot_granularity(phi, opt_to_original, name):\n",
    "    x_count_grans = [get_opt_x_close_to_th_count(opt_res.x)[0] for topic, opt_res in opt_to_original.iteritems()]\n",
    "    x_count_grans_mean = np.mean(x_count_grans)\n",
    "    x_count_grans_th = [get_opt_x_close_to_th_count(opt_res.x, cut_th=5*1e-2)[0] for topic, opt_res in opt_to_original.iteritems()]\n",
    "    x_count_grans_mean_th = np.mean(x_count_grans_th)\n",
    "    grans = [get_words_close_to_th_count(col)[0] for topic, col in phi.iteritems()]\n",
    "    grans_mean = np.mean(grans) \n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharey=False, figsize=(15,5))\n",
    "    sns.distplot(x_count_grans, color='r', bins=5, ax=ax1)\n",
    "    sns.distplot(x_count_grans_th, color='b', bins=5, ax=ax1)\n",
    "    for topic, opt_res in opt_to_original.iteritems():\n",
    "        ax2.plot(sorted(opt_res.x)[::-1])\n",
    "    sns.distplot(grans, color='r', bins=5, ax=ax3)\n",
    "    title = '{} {} \\nx_count_grans_mean = {}; th={}'.format(name, phi.shape, x_count_grans_mean, x_count_grans_mean_th)\n",
    "    ax1.set_title(title)\n",
    "    title = '{} {} \\ngrans_mean = {}'.format(name, phi.shape, grans_mean)\n",
    "    ax3.set_title(title)\n",
    "\n",
    "    return x_count_grans, x_count_grans_mean, grans, grans_mean\n",
    "\n",
    "def plot_different_distances(different_distances, title):\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharey=False, figsize=(15,5))\n",
    "    \n",
    "    if dh.kl_dist in different_distances.keys():\n",
    "        vals = different_distances[dh.kl_dist].values.flatten()\n",
    "        sns.distplot(vals, color='y', ax=ax1, label='kl')\n",
    "    if dh.kl_sym_dist in different_distances.keys():\n",
    "        vals = different_distances[dh.kl_sym_dist].values.flatten()\n",
    "        sns.distplot(vals, color='m', ax=ax1, label='kl_sym')\n",
    "    \n",
    "    vals = different_distances[dh.jaccard_dist].values.flatten()\n",
    "    sns.distplot(vals, color='r', ax=ax2, label='jaccard')\n",
    "    plt.xlim(0.6, 1)\n",
    "    sns.distplot(vals, color='r', ax=ax3, label='jaccard')\n",
    "\n",
    "    vals = different_distances[dh.cos_dist].values.flatten()\n",
    "    sns.distplot(vals,  color='b', ax=ax2, label='cos')\n",
    "    plt.xlim(0.6, 1)\n",
    "    sns.distplot(vals, color='b', ax=ax3, label='cos')\n",
    "\n",
    "    vals = different_distances[dh.hellinger_dist].values.flatten()\n",
    "    sns.distplot(vals, color='g', ax=ax2, label='hellinger')\n",
    "    plt.xlim(0.6, 1)\n",
    "    sns.distplot(vals, color='g', ax=ax3, label='hellinger')\n",
    "    ax1.legend()\n",
    "    ax2.legend()    \n",
    "    if title != '':\n",
    "        fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    \n",
    "def get_distances(phi):\n",
    "    different_distances = {}\n",
    "    distances = [dh.jaccard_dist, dh.cos_dist, dh.hellinger_dist, dh.kl_dist, dh.kl_sym_dist]\n",
    "    for dist_fn in distances:\n",
    "        different_distances[dist_fn] = dh.calculate_distances(dist_fn, phi, phi)\n",
    "    return different_distances\n",
    "def save_and_plot(idx, names_list, phi_convex_hull_list, iterations_info_list, iterations_filtering_list):\n",
    "    save_pickle_file(phi_convex_hull_list[idx], 'phi_convex_hull___' + names_list[idx])\n",
    "    save_pickle_file(iterations_info_list[idx], 'iterations_info_list___' + names_list[idx])\n",
    "    save_pickle_file(iterations_filtering_list[idx], 'iterations_filtering_list___' + names_list[idx])\n",
    "\n",
    "    plot_convex_hull_topics_iterations_distribution(phi_convex_hull_list[idx])\n",
    "    plot_convex_hull_columns_change(iterations_info_list[idx])\n",
    "\n",
    "    distances_to_original_list = bchh.calculate_distances(DIST_FN, phi_convex_hull_list[idx], phi_original)\n",
    "    opt_res_to_original_list = bchh.get_optimization_result(DIST_FN, None, phi_convex_hull_list[idx], phi_original,\n",
    "                                                       distances_to_original_list[idx], n_closest_topics=N_CLOSEST_TOPICS_COUNT)\n",
    "    opt_original_to_res_list = bchh.get_optimization_result(DIST_FN, None, phi_original,  phi_convex_hull_list[idx],\n",
    "                                                       distances_to_original_list[idx].T, n_closest_topics=N_CLOSEST_TOPICS_COUNT)\n",
    "\n",
    "    _,_,_,_ = get_and_plot_granularity(phi_convex_hull_list[idx], opt_res_to_original_list[idx], names_list[idx])\n",
    "    _,_,_,_ = get_and_plot_granularity(phi_convex_hull_list[idx], opt_original_to_res_list[idx], names_list[idx])\n",
    "    plot_dists(opt_res_to_original_list[idx], opt_original_to_res_list[idx], names_list[idx])\n",
    "    \n",
    "    different_distances = get_distances(phi_convex_hull_list[idx])\n",
    "    different_distances_to_original = tvsoch.get_test_to_original_result_different_distances(phi_convex_hull_list[idx], phi_convex_hull_list[idx])\n",
    "    tvsoch.plot_original_columns_count_different_distances(different_distances_to_original, n_original_columns_count=100)\n",
    "    plot_different_distances(different_distances)\n",
    "    return distances_to_original_list, opt_res_to_original_list, opt_original_to_res_list, different_distances, different_distances_to_original\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим оригинальный sample датасет (от model3), до этого скопировав в папку с batches нужные pickle файлы модели.\n",
    "Сначала провизуалируем по одной итерации каждой новой модели, а потом будем итерационно строить выпуклую оболочку для каждой модели по отдельности и затем сравнивать их. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phi_original, theta_original = load_pickle_file('phi_model2.p', config.output_batches_path), load_pickle_file('theta_model2.p', config.output_batches_path)\n",
    "phi_nwt_original = pd.DataFrame(0, index=phi_original.index, columns=[])\n",
    "print phi_original.shape, theta_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_topic_ok(topic_phi, _debug=False):\n",
    "    if type(topic_phi) != np.ndarray:\n",
    "        topic_phi = np.array(topic_phi)\n",
    "    significant_element_th_large, significant_element_th_small = 0.01, 0.005\n",
    "    significant_elements_count_large, significant_elements_count_small = 5, 10\n",
    "    # sum must be != 0 (after regulizators some topics may be zero)\n",
    "    topic_sum_rule = np.sum(topic_phi) > 1e-1\n",
    "    # topic must have at least n words with probability greater that th\n",
    "    topic_significant_elements_count_large = len(np.where(topic_phi > significant_element_th_large)[0])\n",
    "    topic_significant_elements_count_small = len(np.where(topic_phi > significant_element_th_small)[0])\n",
    "    topic_significant_elements_large_rule = topic_significant_elements_count_large >= significant_elements_count_large\n",
    "    topic_significant_elements_small_rule = topic_significant_elements_count_small >= significant_elements_count_small\n",
    "    topic_docs_count_rule = None\n",
    "    if _debug:\n",
    "        print('topic_sum_rule = {} [{}], topic_significant_elements_large_rule = {} [{}], topic_significant_elements_small_rule = {} [{}]' \\\n",
    "              .format(topic_sum_rule, np.sum(topic_phi), \n",
    "                      topic_significant_elements_large_rule, topic_significant_elements_count_large, \n",
    "                      topic_significant_elements_small_rule, topic_significant_elements_count_small))\n",
    "    return topic_sum_rule and topic_significant_elements_large_rule and topic_significant_elements_small_rule\n",
    "\n",
    "def get_distances(phi, distances=[dh.jaccard_dist, dh.cos_dist, dh.hellinger_dist, dh.kl_dist, dh.kl_sym_dist]):\n",
    "    different_distances = {}    \n",
    "    for dist_fn in distances:\n",
    "        print('Processing {}'.format(dist_fn))\n",
    "        tmp = dh.calculate_distances(dist_fn, phi, phi)        \n",
    "        if not np.any(tmp == np.inf) and not np.any(tmp == np.nan):\n",
    "            different_distances[dist_fn] = tmp\n",
    "    return different_distances\n",
    "def reg_experiment(phi_original, phi_test, phi_nwt_original, phi_nwt_test):\n",
    "    different_inter_distances_closest_1, different_inter_distances_closest_2 = None, None\n",
    "    different_inter_distances_1, different_inter_distances_2 = None, None\n",
    "    different_to_original_distances_closest_1, different_to_test_distances_closest_2 = None, None\n",
    "    different_to_original_opts_1, different_to_test_opts_2, models_compare_matrix = None, None, None\n",
    "    try:\n",
    "        ph.print_phi_top_tokens(phi_original, phi_test, n_top_tokens=13)\n",
    "            \n",
    "        models_compare_matrix = ctm.print_models_comparasion(phi_original, phi_test, phi_nwt_original, phi_nwt_test)\n",
    "\n",
    "        % matplotlib inline\n",
    "        different_inter_distances_closest_1 = tvsoch.get_test_to_original_result_different_distances(phi_original, phi_original)\n",
    "        tvsoch.plot_original_columns_count_different_distances(different_inter_distances_closest_1, \n",
    "                                                               n_original_columns_count=phi_original.shape[1], \n",
    "                                                               title='closest by dist inter 1')\n",
    "        different_inter_distances_closest_2 = tvsoch.get_test_to_original_result_different_distances(phi_test, phi_test)\n",
    "        tvsoch.plot_original_columns_count_different_distances(different_inter_distances_closest_2, \n",
    "                                                               n_original_columns_count=phi_test.shape[1],\n",
    "                                                               title='closest by dist inter 2')\n",
    "\n",
    "\n",
    "        different_inter_distances_1 = get_distances(phi_original)\n",
    "        plot_different_distances(different_inter_distances_1, 'inter distances 1')\n",
    "        different_inter_distances_2 = get_distances(phi_test)\n",
    "        plot_different_distances(different_inter_distances_2, 'inter distances 2')\n",
    "\n",
    "\n",
    "        different_to_original_distances_closest_1 = tvsoch.get_test_to_original_result_different_distances(phi_test, phi_original)\n",
    "        tvsoch.plot_original_columns_count_different_distances(different_to_original_distances_closest_1, \n",
    "                                                               n_original_columns_count=phi_original.shape[1],\n",
    "                                                               title='closest by dist test/original')\n",
    "        different_to_test_distances_closest_2 = tvsoch.get_test_to_original_result_different_distances(phi_original, phi_test)\n",
    "        tvsoch.plot_original_columns_count_different_distances(different_to_test_distances_closest_2, \n",
    "                                                               n_original_columns_count=phi_test.shape[1],\n",
    "                                                               title='closest by dist original/test')\n",
    "\n",
    "\n",
    "        different_to_original_opts_1 = tvsoch.get_test_to_original_opt_result_different_distances(phi_test, phi_original,\n",
    "                                        distances=[dh.jaccard_dist, dh.cos_dist, dh.hellinger_dist])\n",
    "        tvsoch.plot_original_columns_count_different_distances(different_to_original_opts_1, \n",
    "                                                               n_original_columns_count=phi_original.shape[1],\n",
    "                                                               title='closest by opt test/original')\n",
    "        different_to_test_opts_2 = tvsoch.get_test_to_original_opt_result_different_distances(phi_original, phi_test,\n",
    "                                        distances=[dh.jaccard_dist, dh.cos_dist, dh.hellinger_dist])\n",
    "        tvsoch.plot_original_columns_count_different_distances(different_to_test_opts_2, \n",
    "                                                               n_original_columns_count=phi_test.shape[1],\n",
    "                                                               title='closest by opt original/test')\n",
    "\n",
    "\n",
    "        print different_to_original_opts_1[dh.hellinger_dist][1][1]\n",
    "        \n",
    "    except Exception as inst:\n",
    "        print('An error happened')\n",
    "        print type(inst)     # the exception instance\n",
    "        print inst.args      # arguments stored in .args\n",
    "        print inst           \n",
    "        ;\n",
    "    return different_inter_distances_closest_1, different_inter_distances_closest_2, \\\n",
    "           different_inter_distances_1, different_inter_distances_2, \\\n",
    "           different_to_original_distances_closest_1, different_to_test_distances_closest_2, \\\n",
    "           different_to_original_opts_1, different_to_test_opts_2, models_compare_matrix\n",
    "def print_phi_top_tokens(phi, topic_name, n_top_tokens=13):\n",
    "    topic = phi.loc[:, topic_name]\n",
    "    top_tokens_and_weight = ' '.join([u'{0}: {1:.3f}'.format(topic, weight) for topic, weight in topic.sort_values()[::-1][0:n_top_tokens].iteritems() if weight != 0])\n",
    "    print(topic_name + '| ' + top_tokens_and_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose models\n",
    "Построить несколько моделей с отбором тем. Выводить число оставшихся необнулившихся колонок фи/тета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_count = 100\n",
    "names_list, models_list = [0] * models_count, [0] * models_count\n",
    "phi_list, phi_nwt_list, theta_list = [0] * models_count, [0] * models_count, [0] * models_count\n",
    "phi_filtered_list, phi_nwt_filtered_list, theta_filtered_list = [0] * models_count, [0] * models_count, [0] * models_count\n",
    "\n",
    "different_inter_distances_closest_1, different_inter_distances_closest_2 = [0] * models_count, [0] * models_count\n",
    "different_inter_distances_1, different_inter_distances_2 = [0] * models_count, [0] * models_count\n",
    "different_to_original_distances_closest_1, different_to_test_distances_closest_2 = [0] * models_count, [0] * models_count\n",
    "different_to_original_opts_1, different_to_test_opts_2, models_compare_matrix = [0] * models_count, [0] * models_count, [0] * models_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 topics\n",
    "## decorrelator only\n",
    "* без обучения сначала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_1(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 1.5\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -1.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -1.5\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 21\n",
    "names_list[idx] = u'model_rch_20_1'\n",
    "models_list[idx] = create_model_rch_20_1(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20 \n",
    "* **kernel size**: 24 vs 94, **purity**: .63 vs .71, **contrast** .78 vs .82, **$phi_{ij}$**:  no \n",
    "* **closest by dist**: примерно так же различны, как и original\n",
    "* **inter distances**: более размазанные\n",
    "\n",
    "|                                  | 0.2 | 0.4 | 0.6 | 0.8 |\n",
    "|:--------------------------------:|:---:|:---:|:---:|:---:|\n",
    "|   closestby dist test/original   |     |  0  |  5  | j18-h20    |\n",
    "|   closest by dist original/test  |     |  0  | < 5 | 20  |\n",
    "| closest by opt res test/original |     |  8  | h20(0.45) |     |\n",
    "| closest by opt res original/test |     |  0  |  0  |  h15 ||\n",
    "* **Выводы**: opt значительно лучше, чем dist, понятно различие в порядке для opt (так как зависит не от одной колонки, а от л/к)\n",
    "* **TODO**: \n",
    "\n",
    "\n",
    "побольше декоррелятор + fit model сначала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_2(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=5, \n",
    "                                  _model_name=model_name)\n",
    "    tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 3\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -1.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -1.5\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 22\n",
    "names_list[idx] = u'model_rch_20_2'\n",
    "models_list[idx] = create_model_rch_20_2(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20\n",
    "* **kernel size**: 24 vs 114, **purity**: .63 vs .68, **contrast** .78 vs .84, **$phi_{ij}$**:  no (более размазанные темы с меньшим числом сильных коэффициентов)\n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|   0 \t|  < 5  |  20  \t|\n",
    "|   closest by dist original/test  \t|     \t|     \t|  h5  \t|  20 \t|\n",
    "| closest by opt res test/original \t|     \t|  h20 \t|     \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|     \t|  0 \t|  18 \t||\n",
    "* **Выводы**: не сильно отличается от предыдущей\n",
    "* **TODO**: \n",
    "\n",
    "Sparse низкий. Попробуем ещё больше декоррелятор сделать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_3(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=5, \n",
    "                                  _model_name=model_name)\n",
    "    tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 10\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -3\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -3\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 23\n",
    "names_list[idx] = u'model_rch_20_3'\n",
    "models_list[idx] = create_model_rch_20_3(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20, 0.90\n",
    "* **kernel size**: 24 vs 114, **purity**: .63 vs .67, **contrast** .78 vs .84, **$phi_{ij}$**:  -+++-\n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|     \t|   5\t|  20  \t|\n",
    "|   closest by dist original/test  \t|     \t|     \t|   5 \t|  20  \t|\n",
    "| closest by opt res test/original \t|     \t|  h20 \t|     \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|   0  \t|   0  \t|  h16 \t||\n",
    "* **Выводы**: тоже не очень отличается от предыдущей\n",
    "* **TODO**: \n",
    "\n",
    "Попробуем убрать обучение сначала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_4(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 6\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -1.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -1.5\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 24\n",
    "names_list[idx] = u'model_rch_20_4'\n",
    "models_list[idx] = create_model_rch_20_4(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20\n",
    "* **kernel size**: 24 vs 94, **purity**: .63 vs .71, **contrast** .78 vs .82, **$phi_{ij}$**:  5\n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|   0  \t|  < 5 \t|  20  \t|\n",
    "|   closest by dist original/test  \t|     \t|   -  \t|   -  \t|   -  \t|\n",
    "| closest by opt res test/original \t|     \t|   15 \t|  h20(0.45) \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|     \t|   0  \t|  h15 \t||\n",
    "* **Выводы**: убрали обучение вначале -> kernel size немного ниже, dist такой же, opt порог выше\n",
    "* **TODO**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic selection only\n",
    "Без обучения в начале, коэф маленький (0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_1_ts(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model.regularizers.add(artm.TopicSelectionThetaRegularizer(name='topic_selection_theta_regularizer'))    \n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['topic_selection_theta_regularizer'].tau = 0.1\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -1.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -1.5\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 31\n",
    "names_list[idx] = u'model_rch_20_1_ts'\n",
    "models_list[idx] = create_model_rch_20_1_ts(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20\n",
    "* **kernel size**: 24 vs 95, **purity**: .63 vs .70, **contrast** .78 vs .81, **$phi_{ij}$**:  \n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|   0  \t|   5  \t|  20  \t|\n",
    "|   closest by dist original/test  \t|     \t|   - \t|   -  \t|  -   \t|\n",
    "| closest by opt res test/original \t|     \t|   0 \t|  h20 \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|     \t|   0  \t|  14  \t||\n",
    "* **Выводы**: немного хуже, чем декор, а так примерно одинаковый, спарсе низкий\n",
    "* **TODO**: \n",
    "\n",
    "Увеличим коэф (с 0 0.1 до 0.5) + начальное обучение без регуляризаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_2_ts(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=5, \n",
    "                                  _model_name=model_name)\n",
    "    tmp_model.regularizers.add(artm.TopicSelectionThetaRegularizer(name='topic_selection_theta_regularizer'))    \n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['topic_selection_theta_regularizer'].tau = 0.5\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -1.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -1.5\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 32\n",
    "names_list[idx] = u'model_rch_20_2_ts'\n",
    "models_list[idx] = create_model_rch_20_2_ts(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20\n",
    "* **kernel size**: 24 vs , **purity**: .63 vs ., **contrast** .78 vs ., **$phi_{ij}$**:  3\n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|   0  \t|   5  \t|  20  \t|\n",
    "|   closest by dist original/test  \t|     \t|   -  \t|   -  \t|  -   \t|\n",
    "| closest by opt res test/original \t|     \t|  h20 \t|     \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|     \t|   0  \t|   14 \t||\n",
    "* **Выводы**: не сильно отличается от пред.\n",
    "* **TODO**: \n",
    "\n",
    "Увеличить спарсе коэффициенты (от -1.5 до -4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_3_ts(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=5, \n",
    "                                  _model_name=model_name)\n",
    "    tmp_model.regularizers.add(artm.TopicSelectionThetaRegularizer(name='topic_selection_theta_regularizer'))    \n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['topic_selection_theta_regularizer'].tau = 0.6\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -4\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -4\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 33\n",
    "names_list[idx] = u'model_rch_20_3_ts'\n",
    "models_list[idx] = create_model_rch_20_3_ts(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> \n",
    "* **kernel size**: 24 vs , **purity**: .63 vs ., **contrast** .78 vs ., **$phi_{ij}$**:  \n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|     \t|     \t|     \t|\n",
    "|   closest by dist original/test  \t|     \t|     \t|     \t|     \t|\n",
    "| closest by opt res test/original \t|     \t|     \t|     \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|     \t|     \t|     \t||\n",
    "* **Выводы**: \n",
    "* **TODO**: \n",
    "\n",
    "Увеличим коэффициент отбора тем от 0.5 до 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_4_ts(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=5, \n",
    "                                  _model_name=model_name)\n",
    "    tmp_model.regularizers.add(artm.TopicSelectionThetaRegularizer(name='topic_selection_theta_regularizer'))    \n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['topic_selection_theta_regularizer'].tau = 0.8\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -4\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -4\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 34\n",
    "names_list[idx] = u'model_rch_20_4_ts'\n",
    "models_list[idx] = create_model_rch_20_4_ts(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 150 -> \n",
    "* **kernel size**: 24 vs , **purity**: .63 vs ., **contrast** .78 vs ., **$phi_{ij}$**:  \n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "* **closest by dist test/original**: 0.2: ; 0.4: ; 0.6: ; 0.8: \n",
    "* **closest by dist original/test**:  0.2: ; 0.4: ; 0.6: ; 0.8: \n",
    "* **closest by opt res test/original**: 0.2: ; 0.4: ; 0.6: ; 0.8: \n",
    "* **closest by opt res original/test**: 0.2: ; 0.4: ; 0.6: ; 0.8: \n",
    "\n",
    "* **Выводы**: \n",
    "* **TODO**: \n",
    "\n",
    "Без регуляризаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_5_ts(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)   \n",
    "    return tmp_model\n",
    "\n",
    "idx = 35\n",
    "names_list[idx] = u'model_rch_20_5_ts'\n",
    "models_list[idx] = create_model_rch_20_5_ts(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20, 0.66\n",
    "* **kernel size**: 24 vs 124, **purity**: .63 vs .71, **contrast** .78 vs .79, **$phi_{ij}$**:  5\n",
    "* **closest by dist**: похож порог, но немного меньше\n",
    "* **inter distances**:\n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|   0  \t|   5 \t|  20  \t|\n",
    "|   closest by dist original/test  \t|     \t|   -  \t|   -  \t|  -  \t|\n",
    "| closest by opt res test/original \t|     \t| h20(0.35)\t|     \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|     \t|   0  \t| 18   \t|\n",
    "* **Выводы**: не очень отличается по dist от с регуляризаторами. по opt даже лучше (порог на 0.5 меньше) - наверное, из-за более общных тем\n",
    "* **TODO**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decorrelator + topic selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_1_decor_ts(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=5, \n",
    "                                  _model_name=model_name)\n",
    "    tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 6\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -2\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -2    \n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=15, \n",
    "                                  _model_name=model_name)\n",
    "    \n",
    "    tmp_model.regularizers.add(artm.TopicSelectionThetaRegularizer(name='topic_selection_theta_regularizer'))    \n",
    "    tmp_model.regularizers['topic_selection_theta_regularizer'].tau = 0.7\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -0.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -0.5\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 0\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 41\n",
    "names_list[idx] = u'create_model_rch_20_1_decor_ts'\n",
    "models_list[idx] = create_model_rch_20_1_decor_ts(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20, 0.9\n",
    "* **kernel size**: 24 vs 112, **purity**: .63 vs .71, **contrast** .78 vs .84, **$phi_{ij}$**: -+++-\n",
    "* **closest by dist**: похожи\n",
    "* **inter distances**: размазанее\n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|     \t|  < 5 \t|  20  \t|\n",
    "|   closest by dist original/test  \t|     \t|     \t|   -  \t|   -  \t|\n",
    "| closest by opt res test/original \t|     \t|  h20 \t|     \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|     \t|   0  \t|  16  \t|\n",
    "* **Выводы**: \n",
    "* **TODO**: \n",
    "\n",
    "Спарсе по -1,5 для сравнения с без топик селектиона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_2_decor_ts(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=5, \n",
    "                                  _model_name=model_name)\n",
    "    tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 6\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -2\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -2    \n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    \n",
    "    tmp_model.regularizers.add(artm.TopicSelectionThetaRegularizer(name='topic_selection_theta_regularizer'))    \n",
    "    tmp_model.regularizers['topic_selection_theta_regularizer'].tau = 0.7\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -0.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -0.5\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 0\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 42\n",
    "names_list[idx] = u'create_model_rch_20_2_decor_ts'\n",
    "models_list[idx] = create_model_rch_20_2_decor_ts(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 20 -> 20, 0.91\n",
    "* **kernel size**: 24 vs , **purity**: .63 vs ., **contrast** .78 vs ., **$phi_{ij}$**: -+++- \n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "\n",
    "|                                  \t| 0.2 \t| 0.4 \t| 0.6 \t| 0.8 \t|\n",
    "|:--------------------------------:\t|:---:\t|:---:\t|:---:\t|:---:\t|\n",
    "|   closestby dist test/original   \t|     \t|   -  \t|  -   \t|  -   \t|\n",
    "|   closest by dist original/test  \t|     \t|     \t|     \t|     \t|\n",
    "| closest by opt res test/original \t|     \t|     \t|     \t|     \t|\n",
    "| closest by opt res original/test \t|     \t|     \t|     \t|     \t|\n",
    "* **Выводы**: вообще не отличается от без topic selection\n",
    "* **TODO**: \n",
    "\n",
    "увеличим топик селекьтон коэф\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_rch_20_3_decor_ts(n_iteration, model_name='', fit=True, n_topics=20):\n",
    "    if model_name is '':\n",
    "        model_name = 'model_tmp_{}'.format(n_topics)\n",
    "    model_name += '_iter_{}'.format(n_iteration)\n",
    "    tmp_model = cmh.create_model(current_dictionary=dictionary, n_topics=n_topics, n_doc_passes=5, seed_value=100 + n_iteration,\n",
    "                                 n_top_tokens=15, p_mass_threshold=0.25)\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=5, \n",
    "                                  _model_name=model_name)\n",
    "    tmp_model.regularizers.add(artm.DecorrelatorPhiRegularizer(name='decorrelator_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparseThetaRegularizer(name='ss_theta_regularizer'))\n",
    "    tmp_model.regularizers.add(artm.SmoothSparsePhiRegularizer(name='ss_phi_regularizer', class_ids=['@default_class']))\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 6\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -1.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -1.5    \n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=15, \n",
    "                                  _model_name=model_name)\n",
    "    \n",
    "    tmp_model.regularizers.add(artm.TopicSelectionThetaRegularizer(name='topic_selection_theta_regularizer'))    \n",
    "    tmp_model.regularizers['topic_selection_theta_regularizer'].tau = 0.9\n",
    "    tmp_model.regularizers['ss_theta_regularizer'].tau = -0.5\n",
    "    tmp_model.regularizers['ss_phi_regularizer'].tau = -0.5\n",
    "    tmp_model.regularizers['decorrelator_phi_regularizer'].tau = 0\n",
    "    tmp_model = cmh.fit_one_model(plot_maker, batch_vectorizer, models_file, config, \n",
    "                                  tmp_model, _n_iterations=25, \n",
    "                                  _model_name=model_name)\n",
    "    return tmp_model\n",
    "\n",
    "idx = 41\n",
    "names_list[idx] = u'create_model_rch_20_3_decor_ts'\n",
    "models_list[idx] = create_model_rch_20_3_decor_ts(0, model_name=names_list[idx])\n",
    "phi_list[idx], phi_nwt_list[idx] = models_list[idx].get_phi(), models_list[idx].get_phi(model_name=models_list[idx].model_nwt)\n",
    "theta_list[idx] = models_list[idx].get_theta()\n",
    "\n",
    "filtered_topics = [topic_name for topic_name, topic in phi_list[idx].iteritems() if check_topic_ok(topic)]\n",
    "print('Filtered topics: ', len(filtered_topics), filtered_topics)\n",
    "if len(filtered_topics):\n",
    "    phi_filtered_list[idx] = phi_list[idx].loc[:, filtered_topics]\n",
    "    phi_nwt_filtered_list[idx] = phi_nwt_list[idx].loc[:, filtered_topics]\n",
    "    theta_filtered_list[idx] = theta_list[idx].loc[filtered_topics, :]\n",
    "\n",
    "    different_inter_distances_closest_1[idx], different_inter_distances_closest_2[idx], \\\n",
    "        different_inter_distances_1[idx], different_inter_distances_2[idx], \\\n",
    "        different_to_original_distances_closest_1[idx], different_to_test_distances_closest_2[idx], \\\n",
    "        different_to_original_opts_1[idx], different_to_test_opts_2[idx], models_compare_matrix[idx] = \\\n",
    "        reg_experiment(phi_original, phi_filtered_list[idx], phi_nwt_original, phi_nwt_filtered_list[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 150 -> \n",
    "* **kernel size**: 24 vs , **purity**: .63 vs ., **contrast** .78 vs ., **$phi_{ij}$**:  \n",
    "* **closest by dist**: \n",
    "* **inter distances**: \n",
    "\n",
    "the same\n",
    "* **Выводы**: \n",
    "* **TODO**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_pickle_file([different_inter_distances_closest_1, different_inter_distances_closest_2, \n",
    "        different_inter_distances_1, different_inter_distances_2, \n",
    "        different_to_original_distances_closest_1, different_to_test_distances_closest_2, \n",
    "        different_to_original_opts_1, different_to_test_opts_2, models_compare_matrix], 'result_20.p')\n",
    "save_pickle_file([names_list, phi_list, phi_nwt_list, theta_list,\n",
    "                  phi_filtered_list, phi_nwt_filtered_list, theta_filtered_list], 'init_20.p')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

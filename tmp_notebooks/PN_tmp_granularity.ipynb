{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Техническая задача: гранулярность по-другому, now: 0.95 может одно слагаемое 0.9, остальные 100 - в сумме 0.05 -> гранулярность 101, а на самом деле хотим 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import artm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "print artm.version()\n",
    "\n",
    "from os import path, mkdir\n",
    "from datetime import datetime\n",
    "sys.path.insert(0, '..\\\\modules\\\\helpers')\n",
    "\n",
    "import distances_helper as dh \n",
    "import print_helper as ph\n",
    "import create_model_helper as cmh\n",
    "import build_convex_hull_helper as bchh\n",
    "import different_models as dm\n",
    "\n",
    "from plot_helper import PlotMaker\n",
    "from config_helper import ConfigPaths\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# granularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phi_granularity(phi):\n",
    "    return np.mean([get_words_close_to_th_count(col)[0] for topic, col in phi.iteritems()])\n",
    "def get_words_close_to_th_count(col, global_th=0.95):\n",
    "    cur_sum, sum_count = 0, 0\n",
    "    for val in col.sort_values()[::-1]:\n",
    "        if cur_sum + val <= global_th:\n",
    "            cur_sum += val\n",
    "            sum_count += 1\n",
    "        else:\n",
    "            break\n",
    "    return sum_count + 1, cur_sum\n",
    "def get_opt_x_granularity(opt):\n",
    "    return np.mean([get_opt_x_close_to_th_count(opt_res.x)[0] for topic, opt_res in opt.iteritems()])\n",
    "def get_opt_x_close_to_th_count(opt_x, cut_th=None, global_th=0.95):\n",
    "    cur_sum, sum_count = 0, 0\n",
    "    opt_x_val = opt_x.copy()\n",
    "    if cut_th != None:\n",
    "        opt_x_val[opt_x_val < cut_th] = 0\n",
    "    for val in sorted(opt_x_val)[::-1]:\n",
    "        if val !=0 and cur_sum + val <= global_th:\n",
    "            cur_sum += val\n",
    "            sum_count += 1\n",
    "        else:\n",
    "            break\n",
    "    return sum_count + 1, cur_sum\n",
    "def get_and_plot_granularity(phi, opt_to_original, name):\n",
    "    x_count_grans = [get_opt_x_close_to_th_count(opt_res.x)[0] for topic, opt_res in opt_to_original.iteritems()]\n",
    "    x_count_grans_mean = np.mean(x_count_grans)\n",
    "    x_count_grans_th = [get_opt_x_close_to_th_count(opt_res.x, cut_th=5*1e-2)[0] for topic, opt_res in opt_to_original.iteritems()]\n",
    "    x_count_grans_mean_th = np.mean(x_count_grans_th)\n",
    "    grans = [get_words_close_to_th_count(col)[0] for topic, col in phi.iteritems()]\n",
    "    grans_mean = np.mean(grans) \n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, sharey=False, figsize=(15,5))\n",
    "    sns.distplot(x_count_grans, color='r', bins=5, ax=ax1)\n",
    "    sns.distplot(x_count_grans_th, color='b', bins=5, ax=ax1)\n",
    "    for topic, opt_res in opt_to_original.iteritems():\n",
    "        ax2.plot(sorted(opt_res.x)[::-1])\n",
    "    sns.distplot(grans, color='r', bins=5, ax=ax3)\n",
    "    title = '{} {} \\nx_count_grans_mean = {}; th={}'.format(name, phi.shape, x_count_grans_mean, x_count_grans_mean_th)\n",
    "    ax1.set_title(title)\n",
    "    title = '{} {} \\ngrans_mean = {}'.format(name, phi.shape, grans_mean)\n",
    "    ax3.set_title(title)\n",
    "\n",
    "    return x_count_grans, x_count_grans_mean, grans, grans_mean\n",
    "def get_distances(phi_original, name):\n",
    "    phi_convex_hull = load_pickle_file(name)\n",
    "    distances_to_original = bchh.calculate_distances(dh.hellinger_dist, phi_convex_hull, phi_original)\n",
    "    inter_distances = bchh.calculate_distances(dh.hellinger_dist, phi_convex_hull, phi_convex_hull)\n",
    "    opt_res_to_original = bchh.get_optimization_result(dh.hellinger_dist, None, phi_convex_hull, phi_original,\n",
    "                                                       distances_to_original, n_closest_topics=N_CLOSEST_TOPICS)\n",
    "    save_pickle_file(distances_to_original, 'distances_to_original__' + name)\n",
    "    save_pickle_file(inter_distances, 'inter_distances__' + name)\n",
    "    save_pickle_file(opt_res_to_original, 'opt_res_to_original__' + name)\n",
    "    return phi_convex_hull, distances_to_original, inter_distances, opt_res_to_original\n",
    "def load_distances(name):\n",
    "    phi_convex_hull = load_pickle_file(name)\n",
    "    distances_to_original = load_pickle_file('distances_to_original__' + name)\n",
    "    inter_distances = load_pickle_file('inter_distances__' + name)\n",
    "    opt_res_to_original = load_pickle_file('opt_res_to_original__' + name)\n",
    "    return phi_convex_hull, distances_to_original, inter_distances, opt_res_to_original\n",
    "# построим распределение полученных distances\n",
    "def plot_dists(distances_to_original, inter_distances, opt_res_to_original, name):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=False, figsize=(15,5))\n",
    "    vals = distances_to_original.values.flatten()\n",
    "    sns.distplot(vals[vals != 0], color='r', ax = ax1, label='Inter distances')\n",
    "    vals = inter_distances.values.flatten()\n",
    "    sns.distplot(vals[vals != 0],  color='b', ax = ax1, label='Distances to original')\n",
    "    ax1.set_title(\"distances  \" + name)\n",
    "    ax1.legend()\n",
    "    sns.distplot([val.fun for val in opt_res_to_original.itervalues()], color='r', bins=10, ax=ax2)\n",
    "    ax2.set_title(\"opts  \" + name)\n",
    "    ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0512932943876 -0.105360515658 -2.30258509299 -4.60517018599 -6.90775527898\n"
     ]
    }
   ],
   "source": [
    "print  np.log(0.95), np.log(0.9), np.log(0.1), np.log(0.01), np.log(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0001\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "test_set_1 = pd.Series([0.9, 0.03, 0.01, 0.001, 0.0001, 0.01, 0.01, 0.01, 0.01, 0.01, 0.009])\n",
    "print np.sum(test_set_1)\n",
    "test_set_2 = [0.5, 0.4, 0.05, 0.02, 0.03]\n",
    "print np.sum(test_set_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 -0.105360515658\n",
      "0.03 -3.50655789732\n",
      "0.01 -4.60517018599\n",
      "0.001 -6.90775527898\n",
      "0.0001 -9.21034037198\n",
      "0.01 -4.60517018599\n",
      "0.01 -4.60517018599\n",
      "0.01 -4.60517018599\n",
      "0.01 -4.60517018599\n",
      "0.01 -4.60517018599\n",
      "0.009 -4.71053070165\n"
     ]
    }
   ],
   "source": [
    "for val in test_set_1:\n",
    "    print val, np.log(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 -0.69314718056\n",
      "0.4 -0.916290731874\n",
      "0.05 -2.99573227355\n",
      "0.02 -3.91202300543\n",
      "0.03 -3.50655789732\n"
     ]
    }
   ],
   "source": [
    "for val in test_set_2:\n",
    "    print val, np.log(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_words_close_to_th_count(test_set_1)[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
